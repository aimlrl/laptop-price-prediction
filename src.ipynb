{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kaggle as kg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as s\n",
    "import pickle\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"USERNAME\"] = \"aimlrl\"\n",
    "os.environ[\"KEY\"] = \"f9fcb3d12c2c4845724a50f0cdeab5ea\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kg.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"kg.api.dataset_download_files(dataset=\"ehtishamsadiq/uncleaned-laptop-price-dataset\",\n",
    "                              path=\"./dataset\",unzip=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"project_root/dataset/laptopData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(labels=data.columns[0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = list(data.columns[0:2]) + list(data.columns[3:5]) + list(data.columns[6:9])\n",
    "NUMERIC_COLUMNS = list(set(data.columns).difference(set(CATEGORICAL_COLUMNS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_column(column_name):\n",
    "\n",
    "    data[column_name].unique()\n",
    "\n",
    "    d = dict()\n",
    "    for value in data[column_name].unique():\n",
    "        d[value] = data[data[column_name] == value][data.columns[-1]].mean()\n",
    "\n",
    "    input_target_df = pd.DataFrame(data={column_name:d.keys(),\"Mean Price\":d.values()})\n",
    "    input_target_df.sort_values(by=\"Mean Price\",inplace=True)\n",
    "    input_target_df.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    data[column_name] = data[column_name].replace(to_replace=list(input_target_df[column_name]),\n",
    "                              value=list(input_target_df.index)).infer_objects(copy=False)\n",
    "    \n",
    "    return dict(zip(list(input_target_df[column_name]),list(input_target_df.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = list(data.columns[0:2]) + list(data.columns[3:5]) + list(data.columns[6:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_label_encodings = dict()\n",
    "\n",
    "for column_name in categorical_columns:\n",
    "\n",
    "    label_encoding_dict = label_encode_column(column_name)\n",
    "    columns_label_encodings[column_name] = label_encoding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"columns_label_encodings.pkl\",\"wb\") as file_handle:\n",
    "    pickle.dump(columns_label_encodings,file_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Ram\"] = data[\"Ram\"].apply(lambda x: float(x.split(\"GB\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"Weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Weight\"].replace(to_replace=\"?\",value=data[\"Weight\"].value_counts().index[0],\n",
    "                       inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Weight\"] = data[\"Weight\"].apply(lambda x: float(x.split(\"kg\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Inches\"].replace(to_replace=\"?\",value=data[\"Inches\"].value_counts().index[0],\n",
    "                       inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Inches\"] = data[\"Inches\"].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = data.corr()\n",
    "upper_traingle_mask = np.triu(np.ones_like(data_corr,dtype=bool))\n",
    "sns.heatmap(data=data_corr,center=0,annot=True,square=True,xticklabels=True,yticklabels=True,mask=upper_traingle_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(data_corr[data_corr[data.columns[-1]] > 0.5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data = data[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose = np.array(refined_data.iloc[:,0:6])\n",
    "y = np.array(refined_data.iloc[:,-1]).reshape(refined_data.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineered_feaures(X_transpose,features_degree,is_only_interaction):\n",
    "\n",
    "    nth_degree_feature_engineer = PolynomialFeatures(degree=features_degree,interaction_only=is_only_interaction)\n",
    "    X_transpose_engineered = nth_degree_feature_engineer.fit_transform(X_transpose)\n",
    "\n",
    "    return X_transpose_engineered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_transpose):\n",
    "\n",
    "    zero_mean_one_std_scaler = StandardScaler()\n",
    "    X_bar_transpose = zero_mean_one_std_scaler.fit_transform(X_transpose)\n",
    "\n",
    "    return X_bar_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cv_test_split(X_transpose, y, train_frac, cv_frac):\n",
    "\n",
    "    X_train_transpose = X_transpose[0:int(train_frac*X_transpose.shape[0])]\n",
    "    y_train = y[0:int(train_frac*y.shape[0])]\n",
    "\n",
    "    X_cv_transpose = X_transpose[int(train_frac*X_transpose.shape[0]):int((train_frac+cv_frac)*X_transpose.shape[0])]\n",
    "    y_cv = y[int(train_frac*y.shape[0]):int(train_frac+cv_frac*y.shape[0])]\n",
    "\n",
    "    X_test_transpose = X_transpose[int((train_frac+cv_frac)*X_transpose.shape[0]):]\n",
    "    y_test = y[int((train_frac+cv_frac)*y.shape[0]):]\n",
    "\n",
    "    return (X_train_transpose,y_train), (X_cv_transpose,y_cv), (X_test_transpose,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Price of a Used Laptop\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Price of a Used Laptop\")\n",
    "sns.distplot(y,fit=s.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Log Transformed Price of a Used Laptop\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.hist(np.log(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Log Transformed Price of a Used Laptop\")\n",
    "sns.distplot(np.log(y),fit=s.norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transpose_engineered = engineered_feaures(X_transpose,2,False)\n",
    "X_bar_transpose = normalize_data(X_transpose_engineered)\n",
    "(X_train_transpose,y_train), (X_cv_transpose,y_cv), (X_test_transpose,y_test) = train_cv_test_split(X_bar_transpose,y,0.7,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(theta0,theta):\n",
    "\n",
    "    return np.mean((y_train - (theta0 + np.matmul(X_train_transpose,theta)))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_mse_by_del_theta(theta0,theta):\n",
    "\n",
    "    error_transpose = np.transpose((theta0 + np.matmul(X_train_transpose,theta) - y_train))\n",
    "\n",
    "    del_by_del_theta0 = np.mean(error_transpose)\n",
    "    del_by_del_theta = (1/y_train.shape[0])*np.transpose(np.matmul(error_transpose,X_train_transpose))\n",
    "\n",
    "    return [del_by_del_theta0,del_by_del_theta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(epsilon=10**(-4),epoch_counter=0,theta0_initial=0,\n",
    "             theta_initial = np.zeros((X_train_transpose.shape[1],1)),tol=10**(-5)):\n",
    "\n",
    "    while True:\n",
    "\n",
    "        initial_gradients = del_mse_by_del_theta(theta0_initial,theta_initial)\n",
    "\n",
    "        theta0_final = theta0_initial - (epsilon * initial_gradients[0])\n",
    "        theta_final = theta_initial - (epsilon * initial_gradients[1])\n",
    "\n",
    "        mse_initial_value = mse(theta0_initial,theta_initial)\n",
    "        mse_final_value = mse(theta0_final,theta_final)\n",
    "\n",
    "        if abs(mse_initial_value - mse_final_value) < tol:\n",
    "            break\n",
    "\n",
    "        epoch_counter += 1\n",
    "\n",
    "        theta0_initial = theta0_final\n",
    "        theta_initial = theta_final\n",
    "\n",
    "        print(\"Epoch # {}, MSE Value = {}\".format(epoch_counter,mse_initial_value))\n",
    "\n",
    "    return [theta0_final,theta_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
